{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyP5anLDWe+mTQpMGHra5dYr",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mathjams/AAAI26/blob/main/trainer.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gSx0x7u9w2_y"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "from typing import List, Tuple, Optional, Union, Dict\n",
        "from collator import make_bag_batches, make_bag_windows\n",
        "from transformers import PatchTSTModel\n",
        "import torch.nn.functional as F\n",
        "def _pool_scores_for_bag(scores_1d: torch.Tensor, k: int = 1, top_p: float = None) -> torch.Tensor:\n",
        "    \"\"\"\n",
        "    scores_1d: (Ni,)\n",
        "    If top_p is provided (0<p<=1), use mean of top ceil(p*Ni) scores.\n",
        "    Else fall back to top-k mean with k capped by Ni.\n",
        "    \"\"\"\n",
        "    Ni = scores_1d.numel()\n",
        "    if Ni == 0:\n",
        "        return scores_1d.new_tensor(0.0)\n",
        "    if top_p is not None:\n",
        "        n_keep = max(1, int(np.ceil(top_p * Ni)))\n",
        "        top_vals, _ = torch.topk(scores_1d, n_keep)\n",
        "        return top_vals.mean()\n",
        "    k_eff = min(k, Ni)\n",
        "    top_vals, _ = torch.topk(scores_1d, k_eff)\n",
        "    return top_vals.mean()\n",
        "\n",
        "def _count_instances_above(scores_1d: torch.Tensor, inst_threshold: float) -> int:\n",
        "    if scores_1d.numel() == 0:\n",
        "        return 0\n",
        "    return int((scores_1d > inst_threshold).sum().item())\n",
        "\n",
        "def hinge_loss_pm1(\n",
        "    scores: torch.Tensor,           # (B,)\n",
        "    labels_pm1: torch.Tensor,       # (B,) in {-1,+1}\n",
        "    pos_weight: float = 1.0,\n",
        "    neg_weight: float = 1.0,\n",
        "    margin_pos: float = 1.0,\n",
        "    margin_neg: float = 1.0,\n",
        ") -> torch.Tensor:\n",
        "    pos_mask = labels_pm1 > 0\n",
        "    neg_mask = ~pos_mask\n",
        "\n",
        "    if pos_mask.any():\n",
        "        pos_losses = torch.clamp(margin_pos - scores[pos_mask], min=0.0)\n",
        "        pos_loss = pos_losses.mean()\n",
        "    else:\n",
        "        pos_loss = scores.new_tensor(0.0)\n",
        "\n",
        "    if neg_mask.any():\n",
        "        neg_losses = torch.clamp(margin_neg + scores[neg_mask], min=0.0)\n",
        "        neg_loss = neg_losses.mean()\n",
        "    else:\n",
        "        neg_loss = scores.new_tensor(0.0)\n",
        "\n",
        "    denom = (pos_weight > 0) + (neg_weight > 0)\n",
        "    return (pos_weight * pos_loss + neg_weight * neg_loss) / max(denom, 1)\n",
        "import numpy as np\n",
        "import torch\n",
        "\n",
        "@torch.no_grad()\n",
        "def collect_bag_scores(\n",
        "    encoder, mil_head, sequences, labels_tensor, bag_indices,\n",
        "    context_length=64, stride=16, bags_per_batch=8, device=\"cpu\",\n",
        "    pad_short=True, k=1, top_p: float = None\n",
        "):\n",
        "    \"\"\"\n",
        "    Returns concatenated arrays: scores (num_bags,), labels01 (num_bags,)\n",
        "    \"\"\"\n",
        "    from collator import make_bag_batches, make_bag_windows\n",
        "\n",
        "    encoder.to(device).eval()\n",
        "    mil_head.to(device).eval()\n",
        "\n",
        "    all_scores, all_labels = [], []\n",
        "    batches = make_bag_batches(bag_indices, batch_size_bags=bags_per_batch, shuffle=False)\n",
        "\n",
        "    for b_ids in batches:\n",
        "        pv_list, pm_list, gids, batch_labels = [], [], [], []\n",
        "        for bi, bag_id in enumerate(b_ids):\n",
        "            pv, pm = make_bag_windows(\n",
        "                sequences[bag_id], context_length=context_length, stride=stride,\n",
        "                pad_short=pad_short, add_noise=0.0\n",
        "            )\n",
        "            Ni = pv.shape[0]\n",
        "            if Ni == 0:\n",
        "                L = context_length\n",
        "                pv = torch.zeros(1, L, 2, dtype=torch.float32)\n",
        "                pm = torch.zeros(1, L, 2, dtype=torch.bool)\n",
        "                Ni = 1\n",
        "            pv_list.append(pv); pm_list.append(pm)\n",
        "            gids.append(torch.full((Ni,), bi, dtype=torch.long))\n",
        "            batch_labels.append(labels_tensor[bag_id].item())\n",
        "\n",
        "        pv_batch = torch.cat(pv_list, dim=0).to(device)\n",
        "        pm_batch = torch.cat(pm_list, dim=0).to(device)\n",
        "        gids     = torch.cat(gids, dim=0).to(device)\n",
        "        B        = len(b_ids)\n",
        "        y_pm1    = torch.tensor(batch_labels, dtype=torch.float32, device=device)\n",
        "\n",
        "        out = encoder(past_values=pv_batch, past_observed_mask=pm_batch, return_dict=True)\n",
        "        tokens = out.last_hidden_state\n",
        "        instance_scores = mil_head(tokens).squeeze(-1)\n",
        "        bag_scores = []\n",
        "        for bi in range(B):\n",
        "            mask = (gids == bi)\n",
        "            sc = instance_scores[mask]\n",
        "            bag_scores.append(_pool_scores_for_bag(sc, k=k, top_p=top_p))\n",
        "        bag_scores = torch.stack(bag_scores)\n",
        "        \"\"\"\n",
        "        bag_scores = []\n",
        "        for bi in range(B):\n",
        "            mask = (gids == bi)\n",
        "            if mask.any():\n",
        "                s = instance_scores[mask]\n",
        "                k_eff = min(k, s.numel())\n",
        "                bag_scores.append(torch.topk(s, k_eff).values.mean())\n",
        "            else:\n",
        "                bag_scores.append(torch.tensor(0.0, device=device))\n",
        "        bag_scores = torch.stack(bag_scores)  # (B,)\n",
        "        \"\"\"\n",
        "\n",
        "        all_scores.append(bag_scores.detach().cpu())\n",
        "        all_labels.append((y_pm1 > 0).long().cpu())\n",
        "\n",
        "    return torch.cat(all_scores).numpy(), torch.cat(all_labels).numpy()\n",
        "\n",
        "def _threshold_candidates(scores: np.ndarray):\n",
        "    scores = np.asarray(scores)\n",
        "    uniq = np.unique(scores)\n",
        "    if len(uniq) == 0:\n",
        "        return [0.0]\n",
        "    if len(uniq) == 1:\n",
        "        return [float(uniq[0])]\n",
        "    mids = (uniq[:-1] + uniq[1:]) / 2.0\n",
        "    return list(mids) + [float(uniq[0]) - 1e-6, float(uniq[-1]) + 1e-6]\n",
        "\n",
        "def pick_threshold_weighted_f1(scores, labels01, tp_weight: float = 2.0):\n",
        "    \"\"\"\n",
        "    Grid-search a threshold that maximizes TP-weighted F1:\n",
        "      precision = TP / (TP+FP)\n",
        "      recall    = TP / (TP+FN)\n",
        "      F1_w = (1+w) * P * R / (w*P + R)\n",
        "    Returns (best_thr, best_score, stats_dict)\n",
        "    \"\"\"\n",
        "    scores = np.asarray(scores); labels01 = np.asarray(labels01).astype(int)\n",
        "    if scores.size == 0:\n",
        "        return 0.0, 0.0, dict(tp=0, fp=0, tn=0, fn=0)\n",
        "\n",
        "    best_score, best_thr, best_stats = -1.0, 0.0, dict(tp=0, fp=0, tn=0, fn=0)\n",
        "    for thr in _threshold_candidates(scores):\n",
        "        preds = (scores > thr).astype(np.int64)\n",
        "        tp = int(((preds == 1) & (labels01 == 1)).sum())\n",
        "        fp = int(((preds == 1) & (labels01 == 0)).sum())\n",
        "        tn = int(((preds == 0) & (labels01 == 0)).sum())\n",
        "        fn = int(((preds == 0) & (labels01 == 1)).sum())\n",
        "        prec = tp / max(tp + fp, 1)\n",
        "        rec  = tp / max(tp + fn, 1)\n",
        "        w = float(tp_weight)\n",
        "        f1w = (1.0 + w) * prec * rec / max(w * prec + rec, 1e-12)\n",
        "        if f1w > best_score:\n",
        "            best_score, best_thr = f1w, float(thr)\n",
        "            best_stats = dict(tp=tp, fp=fp, tn=tn, fn=fn)\n",
        "    return best_thr, best_score, best_stats\n",
        "\n",
        "def pick_threshold_fbeta(scores, labels01, beta: float = 2.0):\n",
        "    \"\"\"\n",
        "    Standard F_beta threshold search:\n",
        "      F_beta = (1+beta^2) * P * R / (beta^2 * P + R)\n",
        "    Returns (best_thr, best_score, stats_dict)\n",
        "    \"\"\"\n",
        "    scores = np.asarray(scores); labels01 = np.asarray(labels01).astype(int)\n",
        "    if scores.size == 0:\n",
        "        return 0.0, 0.0, dict(tp=0, fp=0, tn=0, fn=0)\n",
        "\n",
        "    beta2 = float(beta) * float(beta)\n",
        "    best_score, best_thr, best_stats = -1.0, 0.0, dict(tp=0, fp=0, tn=0, fn=0)\n",
        "    for thr in _threshold_candidates(scores):\n",
        "        preds = (scores > thr).astype(np.int64)\n",
        "        tp = int(((preds == 1) & (labels01 == 1)).sum())\n",
        "        fp = int(((preds == 1) & (labels01 == 0)).sum())\n",
        "        tn = int(((preds == 0) & (labels01 == 0)).sum())\n",
        "        fn = int(((preds == 0) & (labels01 == 1)).sum())\n",
        "        prec = tp / max(tp + fp, 1)\n",
        "        rec  = tp / max(tp + fn, 1)\n",
        "        fbeta = (1.0 + beta2) * prec * rec / max(beta2 * prec + rec, 1e-12)\n",
        "        if fbeta > best_score:\n",
        "            best_score, best_thr = fbeta, float(thr)\n",
        "            best_stats = dict(tp=tp, fp=fp, tn=tn, fn=fn)\n",
        "    return best_thr, best_score, best_stats\n",
        "\n",
        "def compute_bag_loss(bag_scores, y_pm1, *, loss_type=\"bce\",\n",
        "                     pos_weight=None, gamma_pos=0.0, gamma_neg=2.0,\n",
        "                     alpha_pos=0.5, beta_f=1.0, eps=1e-8):\n",
        "    \"\"\"\n",
        "    bag_scores: logits (B,)\n",
        "    y_pm1: labels in {-1,+1}\n",
        "    \"\"\"\n",
        "    y01 = (y_pm1 > 0).float()  # (B,)\n",
        "\n",
        "    if loss_type == \"bce\":\n",
        "        return F.binary_cross_entropy_with_logits(\n",
        "            bag_scores, y01, pos_weight=pos_weight\n",
        "        )\n",
        "\n",
        "    elif loss_type == \"focal_asym\":\n",
        "        p = torch.sigmoid(bag_scores)\n",
        "        pos = - y01 * ((1 - p) ** gamma_pos) * torch.log(p.clamp_min(eps))\n",
        "        neg = - (1 - y01) * (p ** gamma_neg) * torch.log((1 - p).clamp_min(eps))\n",
        "        return (alpha_pos * pos + (1 - alpha_pos) * neg).mean()\n",
        "\n",
        "    elif loss_type == \"f_beta\":  # differentiable surrogate for Fβ\n",
        "        p = torch.sigmoid(bag_scores)\n",
        "        tp = (p * y01).sum()\n",
        "        fp = (p * (1 - y01)).sum()\n",
        "        fn = ((1 - p) * y01).sum()\n",
        "        precision = tp / (tp + fp + eps)\n",
        "        recall    = tp / (tp + fn + eps)\n",
        "        beta2 = beta_f * beta_f\n",
        "        fbeta = (1 + beta2) * precision * recall / (beta2 * precision + recall + eps)\n",
        "        return 1 - fbeta  # maximize Fβ → minimize 1 - Fβ\n",
        "\n",
        "    elif loss_type == \"hinge_weighted\":\n",
        "        pos_w = (pos_weight if pos_weight is not None else 1.0)\n",
        "        neg_w = (neg_weight if neg_weight is not None else 1.0)  # now defined\n",
        "        w = torch.where(y_pm1 > 0,\n",
        "                        bag_scores.new_tensor(pos_w),\n",
        "                        bag_scores.new_tensor(neg_w))\n",
        "        return (torch.clamp(1.0 - y_pm1 * bag_scores, min=0.0) * w).mean()\n",
        "\n",
        "    else:\n",
        "        raise ValueError(f\"Unknown loss_type={loss_type}\")\n",
        "def train_one_epoch_manual_bag(\n",
        "    encoder: PatchTSTModel,\n",
        "    mil_head: nn.Module,\n",
        "    sequences: List[np.ndarray],\n",
        "    labels_tensor: torch.Tensor,\n",
        "    bag_indices: List[int],\n",
        "    context_length: int = 64,\n",
        "    stride: int = 16,\n",
        "    bags_per_batch: int = 8,\n",
        "    optimizer: Optional[torch.optim.Optimizer] = None,\n",
        "    device: str = \"cpu\",\n",
        "    pad_short: bool = True,\n",
        "    add_noise: float = 0.0,\n",
        "    seed: int = 42,\n",
        "    k: int = 1,\n",
        "    top_p: float = None,\n",
        "    pos_weight: float = 1.0, neg_weight: float = 1.0,\n",
        "    margin_pos: float = 1.0, margin_neg: float = 1.0,\n",
        ") -> float:\n",
        "    encoder.to(device).eval()\n",
        "    mil_head.to(device).train()\n",
        "\n",
        "    total_loss, total_bags = 0.0, 0\n",
        "    batches = make_bag_batches(bag_indices, batch_size_bags=bags_per_batch, shuffle=True, seed=seed)\n",
        "\n",
        "    for b_ids in batches:\n",
        "        pv_list, pm_list, group_ids, batch_labels = [], [], [], []\n",
        "\n",
        "        for bi, bag_id in enumerate(b_ids):\n",
        "            pv, pm = make_bag_windows(\n",
        "                sequences[bag_id], context_length=context_length, stride=stride,\n",
        "                pad_short=pad_short, add_noise=add_noise\n",
        "            )\n",
        "            Ni = pv.shape[0]\n",
        "            if Ni == 0:  # safety for too-short sequences\n",
        "                L = context_length\n",
        "                pv = torch.zeros(1, L, 2, dtype=torch.float32)\n",
        "                pm = torch.zeros(1, L, 2, dtype=torch.bool)\n",
        "                Ni = 1\n",
        "\n",
        "            pv_list.append(pv)\n",
        "            pm_list.append(pm)\n",
        "            group_ids.append(torch.full((Ni,), bi, dtype=torch.long))\n",
        "            batch_labels.append(labels_tensor[bag_id].item())\n",
        "\n",
        "        pv_batch = torch.cat(pv_list, dim=0).to(device)   # (N_total, L, C)\n",
        "        pm_batch = torch.cat(pm_list, dim=0).to(device)   # (N_total, L, C)\n",
        "        gids     = torch.cat(group_ids, dim=0).to(device) # (N_total,)\n",
        "        B        = len(b_ids)\n",
        "        y_pm1    = torch.tensor(batch_labels, dtype=torch.float32, device=device)  # (B,)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            out = encoder(past_values=pv_batch, past_observed_mask=pm_batch, return_dict=True)\n",
        "            tokens = out.last_hidden_state  # (N_total, T_tokens, D)\n",
        "\n",
        "        instance_scores = mil_head(tokens)  # already (N_total,)\n",
        "        assert instance_scores.dim() == 1 and instance_scores.size(0) == pv_batch.size(0), \\\n",
        "            f\"{instance_scores.shape=} vs {pv_batch.shape=}\"\n",
        "        bag_scores = []\n",
        "        for bi in range(B):\n",
        "            mask = (gids == bi)\n",
        "            sc = instance_scores[mask]\n",
        "            bag_scores.append(_pool_scores_for_bag(sc, k=k, top_p=locals().get(\"top_p\", None)))\n",
        "        bag_scores = torch.stack(bag_scores)\n",
        "        \"\"\"\n",
        "        bag_scores = []\n",
        "        for bi in range(B):\n",
        "            mask = (gids == bi)\n",
        "            if mask.any():\n",
        "                scores = instance_scores[mask]\n",
        "                k_eff = min(k, scores.numel())\n",
        "                topk_vals, _ = torch.topk(scores, k_eff)\n",
        "                bag_scores.append(topk_vals.mean())\n",
        "            else:\n",
        "                bag_scores.append(torch.tensor(0.0, device=device))\n",
        "        bag_scores = torch.stack(bag_scores)  # (B,)\n",
        "        \"\"\"\n",
        "        pos_w_val = None  # or a float as above\n",
        "        pos_w = torch.tensor([pos_w_val], device=bag_scores.device) if pos_w_val else None\n",
        "        loss = hinge_loss_pm1(bag_scores, y_pm1,\n",
        "                          pos_weight=pos_weight, neg_weight=neg_weight,\n",
        "                          margin_pos=margin_pos, margin_neg=margin_neg)\n",
        "        optimizer.zero_grad(set_to_none=True)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        total_loss += loss.item() * B\n",
        "        total_bags += B\n",
        "\n",
        "    return total_loss / max(1, total_bags)\n",
        "\n",
        "def _safe_auc(labels_np: np.ndarray, scores_np: np.ndarray) -> Tuple[float, float]:\n",
        "    \"\"\"ROC-AUC and PR-AUC; returns NaN if not computable.\"\"\"\n",
        "    try:\n",
        "        from sklearn.metrics import roc_auc_score, average_precision_score\n",
        "        roc = roc_auc_score(labels_np, scores_np) if len(np.unique(labels_np)) == 2 else float(\"nan\")\n",
        "        pr  = average_precision_score(labels_np, scores_np)\n",
        "        return float(roc), float(pr)\n",
        "    except Exception:\n",
        "        return float(\"nan\"), float(\"nan\")\n",
        "\n",
        "@torch.no_grad()\n",
        "def evaluate_manual_bag(\n",
        "    encoder: PatchTSTModel,\n",
        "    mil_head: torch.nn.Module,\n",
        "    sequences: List[np.ndarray],\n",
        "    labels_tensor: torch.Tensor,\n",
        "    bag_indices: List[int],\n",
        "    context_length: int = 64,\n",
        "    stride: int = 16,\n",
        "    bags_per_batch: int = 8,\n",
        "    device: str = \"cpu\",\n",
        "    pad_short: bool = True,\n",
        "    k: int = 1,\n",
        "    threshold: float = 0.0,\n",
        "    return_confusion: bool = False,\n",
        "    pos_weight: float = 1.0, neg_weight: float = 1.0,\n",
        "    margin_pos: float = 1.0, margin_neg: float = 1.0,\n",
        ") -> Union[Tuple[float, float],\n",
        "           Tuple[float, float, np.ndarray, Dict[str, float]]]:\n",
        "    \"\"\"\n",
        "    Returns:\n",
        "      val_hinge, val_acc\n",
        "      (+ confusion matrix [[TN FP],[FN TP]] and metrics dict if return_confusion=True)\n",
        "    Metrics: precision, recall, specificity, balanced_acc, roc_auc, pr_auc\n",
        "    \"\"\"\n",
        "    encoder.to(device).eval()\n",
        "    mil_head.to(device).eval()\n",
        "\n",
        "    total_hinge, total_acc, total_bags = 0.0, 0, 0\n",
        "    tp = tn = fp = fn = 0\n",
        "\n",
        "    all_scores, all_labels = [], []\n",
        "\n",
        "    batches = make_bag_batches(bag_indices, batch_size_bags=bags_per_batch, shuffle=False)\n",
        "\n",
        "    for b_ids in batches:\n",
        "        pv_list, pm_list, group_ids, batch_labels = [], [], [], []\n",
        "\n",
        "        for bi, bag_id in enumerate(b_ids):\n",
        "            pv, pm = make_bag_windows(\n",
        "                sequences[bag_id], context_length=context_length, stride=stride,\n",
        "                pad_short=pad_short, add_noise=0.0\n",
        "            )\n",
        "            Ni = pv.shape[0]\n",
        "            if Ni == 0:\n",
        "                L = context_length\n",
        "                pv = torch.zeros(1, L, 2, dtype=torch.float32)\n",
        "                pm = torch.zeros(1, L, 2, dtype=torch.bool)\n",
        "                Ni = 1\n",
        "\n",
        "            pv_list.append(pv)\n",
        "            pm_list.append(pm)\n",
        "            group_ids.append(torch.full((Ni,), bi, dtype=torch.long))\n",
        "            batch_labels.append(labels_tensor[bag_id].item())\n",
        "\n",
        "        pv_batch = torch.cat(pv_list, dim=0).to(device)\n",
        "        pm_batch = torch.cat(pm_list, dim=0).to(device)\n",
        "        gids     = torch.cat(group_ids, dim=0).to(device)\n",
        "        B        = len(b_ids)\n",
        "        y_pm1    = torch.tensor(batch_labels, dtype=torch.float32, device=device)  # (B,)\n",
        "\n",
        "        out = encoder(past_values=pv_batch, past_observed_mask=pm_batch, return_dict=True)\n",
        "        tokens = out.last_hidden_state            # (N_total, T, D)\n",
        "        instance_scores = mil_head(tokens)  # already (N_total,)\n",
        "        assert instance_scores.dim() == 1 and instance_scores.size(0) == pv_batch.size(0), \\\n",
        "            f\"{instance_scores.shape=} vs {pv_batch.shape=}\"\n",
        "        bag_scores_list = []\n",
        "        for bi in range(B):\n",
        "            mask = (gids == bi)\n",
        "            if mask.any():\n",
        "                scores = instance_scores[mask]\n",
        "                k_eff = min(k, scores.numel())\n",
        "                topk_vals, _ = torch.topk(scores, k_eff)\n",
        "                bag_scores_list.append(topk_vals.mean())\n",
        "            else:\n",
        "                bag_scores_list.append(torch.tensor(0.0, device=device))\n",
        "        bag_scores = torch.stack(bag_scores_list)  # (B,)\n",
        "\n",
        "        pos_w_val = None  # or a float as above\n",
        "        pos_w = torch.tensor([pos_w_val], device=bag_scores.device) if pos_w_val else None\n",
        "        loss = hinge_loss_pm1(bag_scores, y_pm1,\n",
        "                           pos_weight=pos_weight, neg_weight=neg_weight,\n",
        "                           margin_pos=margin_pos, margin_neg=margin_neg)\n",
        "        total_hinge += loss.item() * B\n",
        "\n",
        "        targets = (y_pm1 > 0).long()                  # (B,)\n",
        "        preds   = (bag_scores > threshold).long()     # (B,)\n",
        "\n",
        "        total_acc  += (preds == targets).sum().item()\n",
        "        total_bags += B\n",
        "\n",
        "        tp += ((preds == 1) & (targets == 1)).sum().item()\n",
        "        tn += ((preds == 0) & (targets == 0)).sum().item()\n",
        "        fp += ((preds == 1) & (targets == 0)).sum().item()\n",
        "        fn += ((preds == 0) & (targets == 1)).sum().item()\n",
        "\n",
        "        all_scores.append(bag_scores.detach().cpu())\n",
        "        all_labels.append(targets.detach().cpu())\n",
        "\n",
        "    val_hinge = total_hinge / max(1, total_bags)\n",
        "    val_acc   = total_acc  / max(1, total_bags)\n",
        "\n",
        "    if not return_confusion:\n",
        "        return val_hinge, val_acc\n",
        "\n",
        "    cm = np.array([[tn, fp],\n",
        "                   [fn, tp]], dtype=int)\n",
        "\n",
        "    precision     = tp / max(tp + fp, 1)\n",
        "    recall        = tp / max(tp + fn, 1)          # sensitivity\n",
        "    specificity   = tn / max(tn + fp, 1)\n",
        "    balanced_acc  = 0.5 * (recall + specificity)\n",
        "\n",
        "    scores_np = torch.cat(all_scores).numpy()\n",
        "    labels_np = torch.cat(all_labels).numpy()\n",
        "    roc_auc, pr_auc = _safe_auc(labels_np, scores_np)\n",
        "\n",
        "    metrics = dict(\n",
        "        precision=float(precision),\n",
        "        recall=float(recall),\n",
        "        specificity=float(specificity),\n",
        "        balanced_acc=float(balanced_acc),\n",
        "        roc_auc=float(roc_auc),\n",
        "        pr_auc=float(pr_auc),\n",
        "    )\n",
        "    return val_hinge, val_acc, cm, metrics\n"
      ]
    }
  ]
}