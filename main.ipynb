{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mathjams/AAAI26/blob/main/main.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QzyWnABjxVgf"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from transformers import TimeSeriesTransformerModel, TimeSeriesTransformerConfig"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LP2CQkDbxVgj"
      },
      "outputs": [],
      "source": [
        "import importlib"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dVYLB66GxVgj",
        "outputId": "7f3016f0-4c13-4bba-b359-7c049d981d1d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import dataextract\n",
        "importlib.reload(dataextract)\n",
        "resulteye0, resulthand0, maxlen0 = dataextract.plainsequences('ASD')\n",
        "resulteye1, resulthand1, maxlen1 = dataextract.plainsequences('TD')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jjWj5rJXxVgk",
        "outputId": "bd36f4b6-ed1e-4f32-dffd-420fdc5eab4a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(24, 50)"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(resulteye0), len(resulteye1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AyEeMpkNxVgk",
        "outputId": "0092e75d-53f4-40ee-eff9-fec104939245"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "150.54054054054055\n"
          ]
        }
      ],
      "source": [
        "total = 0\n",
        "sum = 0\n",
        "for i in range(len(resulteye0)):\n",
        "    sum+=len(resulteye0[i])\n",
        "    total+=1\n",
        "for i in range(len(resulteye1)):\n",
        "    sum+=len(resulteye1[i])\n",
        "    total+=1\n",
        "print(sum/total)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L8HEMpxxxVgm"
      },
      "outputs": [],
      "source": [
        "eyes = resulteye0+resulteye1\n",
        "hands = resulthand0+resulthand1\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "th2YvV23xVgm",
        "outputId": "092f4cbe-7c00-4288-c1b8-6eb1a70aaf21"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://download.pytorch.org/whl/cpu\n",
            "Requirement already satisfied: torch in /opt/anaconda3/lib/python3.9/site-packages (2.2.2)\n",
            "Requirement already satisfied: torchvision in /opt/anaconda3/lib/python3.9/site-packages (0.17.2)\n",
            "Requirement already satisfied: torchaudio in /opt/anaconda3/lib/python3.9/site-packages (2.2.2)\n",
            "Requirement already satisfied: filelock in /opt/anaconda3/lib/python3.9/site-packages (from torch) (3.13.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /opt/anaconda3/lib/python3.9/site-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: sympy in /opt/anaconda3/lib/python3.9/site-packages (from torch) (1.13.3)\n",
            "Requirement already satisfied: networkx in /opt/anaconda3/lib/python3.9/site-packages (from torch) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /opt/anaconda3/lib/python3.9/site-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /opt/anaconda3/lib/python3.9/site-packages (from torch) (2024.12.0)\n",
            "Requirement already satisfied: numpy in /opt/anaconda3/lib/python3.9/site-packages (from torchvision) (1.26.4)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /opt/anaconda3/lib/python3.9/site-packages (from torchvision) (11.0.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /opt/anaconda3/lib/python3.9/site-packages (from jinja2->torch) (3.0.2)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/anaconda3/lib/python3.9/site-packages (from sympy->torch) (1.3.0)\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "pip install --index-url https://download.pytorch.org/whl/cpu torch torchvision torchaudio\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "umNFZPUixVgn",
        "outputId": "180c7d55-0789-46de-8d8f-f7c9e9f460e4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2.2.2\n",
            "/opt/anaconda3/lib/python3.9/site-packages/torch/__init__.py\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "print(torch.__version__)\n",
        "print(torch.__file__)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qqNrjM6jxVgn"
      },
      "outputs": [],
      "source": [
        "# --- imports / data ---\n",
        "import os, csv, time, importlib\n",
        "import torch\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "sequences = eyes\n",
        "labels = [1]*len(resulteye0) + [-1]*len(resulteye1)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QlrLmJwbxVgo"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ofcAeoElxVgo"
      },
      "outputs": [],
      "source": [
        "#sample sequences\n",
        "newseq = []\n",
        "newlabels = []\n",
        "for i in range(len(sequences)):\n",
        "    if len(sequences[i])<90:\n",
        "        newseq.append(sequences[i])\n",
        "        newlabels.append(labels[i])\n",
        "    else:\n",
        "        endpoint = 90\n",
        "        while endpoint+45<len(sequences[i]):\n",
        "            newseq.append(sequences[i][endpoint-45:endpoint])\n",
        "            newlabels.append(labels[i])\n",
        "            endpoint+=45\n",
        "        newseq.append(sequences[i][endpoint-45:len(sequences[i])])\n",
        "        newlabels.append(labels[i])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1SCfHu2xxVgo",
        "outputId": "d1816b87-622f-42e8-d244-76c4057e5bfe"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "146 146\n"
          ]
        }
      ],
      "source": [
        "print(len(newseq), len(newlabels))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U-HedhKYxVgp"
      },
      "outputs": [],
      "source": [
        "sequences = newseq\n",
        "labels = newlabels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lk7K5qyPxVgp",
        "outputId": "24bf38d1-5cd8-456f-e714-290d7380a582"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/opt/anaconda3/lib/python3.9/site-packages/huggingface_hub/file_download.py:896: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "/opt/anaconda3/lib/python3.9/site-packages/torch/nn/modules/lazy.py:181: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.\n",
            "  warnings.warn('Lazy modules are a new feature under heavy development '\n"
          ]
        }
      ],
      "source": [
        "\n",
        "import collator\n",
        "importlib.reload(collator)\n",
        "\n",
        "all_ids = list(range(len(sequences)))\n",
        "train_ids, val_ids = collator.stratified_split(all_ids, labels, test_size=0.3, seed=42)\n",
        "\n",
        "import modeling\n",
        "importlib.reload(modeling)\n",
        "\n",
        "context_length = 53\n",
        "slide_stride   = 16\n",
        "encoder, cfg = modeling.build_frozen_patchtst(\n",
        "    repo_id=\"namctin/patchtst_etth1_pretrain\",\n",
        "    num_input_channels=2,\n",
        "    context_length=context_length,\n",
        "    patch_length=12,\n",
        "    patch_stride=1,\n",
        "    use_cls_token=True,\n",
        ")\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "encoder.to(device).eval()\n",
        "\n",
        "import mil\n",
        "importlib.reload(mil)\n",
        "\n",
        "mil_head = mil.MILHead2D(\n",
        "    d_model=encoder.config.d_model,\n",
        "    use_cls_token=True,\n",
        "    dropout=0.3,\n",
        ").to(device)\n",
        "\n",
        "decay, no_decay = [], []\n",
        "for n,p in mil_head.named_parameters():\n",
        "    (no_decay if ('bias' in n or 'score_bias' in n) else decay).append(p)\n",
        "\n",
        "optimizer = torch.optim.AdamW(\n",
        "    [{\"params\": decay, \"weight_decay\": 1e-6, \"lr\": 3e-4},\n",
        "     {\"params\": no_decay, \"weight_decay\": 0.0, \"lr\": 3e-4}]\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XZlhRH-UxVgp"
      },
      "outputs": [],
      "source": [
        "import os, csv, time, importlib\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "\n",
        "import trainer\n",
        "importlib.reload(trainer)\n",
        "import confusionplot\n",
        "\n",
        "labels_tensor = torch.tensor(labels, dtype=torch.long)\n",
        "\n",
        "POS_W = 1.8    # loss/metrics weight for ASD\n",
        "NEG_W = 1.0\n",
        "TP_W  = POS_W   # how much to upweight *true positives* when computing TP-weighted F1\n",
        "TOP_P = 0.10\n",
        "MARGIN_POS = 1.0\n",
        "MARGIN_NEG = 1.0\n",
        "\n",
        "TOP_K = 1         # instance aggregator\n",
        "THRESH = 0.0      # (will be updated each epoch by train calibration)\n",
        "\n",
        "run_dir = \"mil_runs\"\n",
        "os.makedirs(run_dir, exist_ok=True)\n",
        "cur_ts = time.strftime(\"%Y%m%d-%H%M%S\")\n",
        "tag    = f\"bag_manual_{cur_ts}\"\n",
        "\n",
        "csv_path         = os.path.join(run_dir, f\"{tag}.csv\")\n",
        "curves_png_loss  = os.path.join(run_dir, f\"{tag}_loss.png\")\n",
        "curves_png_acc   = os.path.join(run_dir, f\"{tag}_acc.png\")\n",
        "\n",
        "best_hinge_ckpt_path     = os.path.join(run_dir, f\"{tag}_bestHinge.pt\")\n",
        "best_hinge_cm_png        = os.path.join(run_dir, f\"{tag}_val_confusion_bestHinge.png\")\n",
        "best_hinge_cm_norm_png   = os.path.join(run_dir, f\"{tag}_val_confusion_bestHinge_norm.png\")\n",
        "best_hinge_csv_path      = os.path.join(run_dir, f\"{tag}_bestHinge.csv\")\n",
        "\n",
        "best_tpf1_ckpt_path      = os.path.join(run_dir, f\"{tag}_bestTPF1.pt\")\n",
        "best_tpf1_cm_png         = os.path.join(run_dir, f\"{tag}_val_confusion_bestTPF1.png\")\n",
        "best_tpf1_cm_norm_png    = os.path.join(run_dir, f\"{tag}_val_confusion_bestTPF1_norm.png\")\n",
        "best_tpf1_csv_path       = os.path.join(run_dir, f\"{tag}_bestTPF1.csv\")\n",
        "\n",
        "hist = {\n",
        "    \"epoch\": [],\n",
        "    \"train_hinge\": [],\n",
        "    \"train_acc\": [],\n",
        "    \"val_hinge\": [],\n",
        "    \"val_acc\": [],\n",
        "    \"val_bal_acc\": [],\n",
        "    \"val_precision\": [],\n",
        "    \"val_recall\": [],\n",
        "    \"val_roc_auc\": [],\n",
        "    \"val_pr_auc\": [],\n",
        "    \"val_f1\": [],\n",
        "    \"val_weighted_acc\": [],\n",
        "    \"val_tpf1\": [],          # TP-weighted F1 (on validation, using train-calibrated threshold)\n",
        "    \"train_threshold\": [],   # track calibrated threshold per epoch\n",
        "}\n",
        "\n",
        "epochs = 200\n",
        "bags_per_batch = 8\n",
        "\n",
        "best_val_hinge_seen = float(\"inf\")\n",
        "best_hinge_state = None\n",
        "best_hinge_epoch = -1\n",
        "\n",
        "best_tpf1_seen = -1.0\n",
        "best_tpf1_state = None\n",
        "best_tpf1_epoch = -1\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    train_hinge = trainer.train_one_epoch_manual_bag(\n",
        "        encoder=encoder, mil_head=mil_head,\n",
        "        sequences=sequences, labels_tensor=labels_tensor,\n",
        "        bag_indices=train_ids,\n",
        "        context_length=context_length, stride=slide_stride,\n",
        "        bags_per_batch=bags_per_batch, optimizer=optimizer,\n",
        "        device=device, pad_short=True, add_noise=0.0, seed=42+epoch,\n",
        "        k=TOP_K,\n",
        "        top_p=TOP_P,\n",
        "        pos_weight=POS_W, neg_weight=NEG_W,\n",
        "        margin_pos=MARGIN_POS, margin_neg=MARGIN_NEG,\n",
        "    )\n",
        "\n",
        "    train_hinge_eval, train_acc = trainer.evaluate_manual_bag(\n",
        "        encoder=encoder, mil_head=mil_head,\n",
        "        sequences=sequences, labels_tensor=labels_tensor,\n",
        "        bag_indices=train_ids,\n",
        "        context_length=context_length, stride=slide_stride,\n",
        "        bags_per_batch=bags_per_batch, device=device,\n",
        "        pad_short=True, k=TOP_K, threshold=THRESH, return_confusion=False,\n",
        "        pos_weight=POS_W, neg_weight=NEG_W, margin_pos=MARGIN_POS, margin_neg=MARGIN_NEG,\n",
        "    )\n",
        "\n",
        "    try:\n",
        "        train_scores, train_y = trainer.collect_bag_scores(\n",
        "            encoder=encoder, mil_head=mil_head,\n",
        "            sequences=sequences, labels_tensor=labels_tensor,\n",
        "            bag_indices=train_ids, context_length=context_length,\n",
        "            stride=slide_stride, bags_per_batch=bags_per_batch,\n",
        "            device=device, pad_short=True, k=TOP_K, top_p=TOP_P\n",
        "        )\n",
        "        THRESH, f1w_train, tstats = trainer.pick_threshold_weighted_f1(\n",
        "            train_scores, train_y, tp_weight=TP_W  # try 2–5\n",
        "        )\n",
        "    except Exception as e:\n",
        "        print(\"[warn] threshold calibration failed; using 0.0. Error:\", e)\n",
        "        THRESH, f1w_train, tstats = 0.0, 0.0, {\"tp\":0,\"fp\":0,\"tn\":0,\"fn\":0}\n",
        "\n",
        "    val_hinge, val_acc, val_cm, val_metrics = trainer.evaluate_manual_bag(\n",
        "        encoder=encoder, mil_head=mil_head,\n",
        "        sequences=sequences, labels_tensor=labels_tensor,\n",
        "        bag_indices=val_ids, context_length=context_length,\n",
        "        stride=slide_stride, bags_per_batch=bags_per_batch,\n",
        "        device=device, pad_short=True, k=TOP_K,\n",
        "        threshold=float(THRESH), return_confusion=True,\n",
        "        pos_weight=POS_W, neg_weight=NEG_W, margin_pos=MARGIN_POS, margin_neg=MARGIN_NEG,\n",
        "    )\n",
        "\n",
        "    prec = float(val_metrics[\"precision\"])\n",
        "    rec  = float(val_metrics[\"recall\"])\n",
        "    f1   = (2.0 * prec * rec / (prec + rec)) if (prec + rec) > 0 else 0.0\n",
        "\n",
        "    tn, fp = int(val_cm[0, 0]), int(val_cm[0, 1])\n",
        "    fn, tp = int(val_cm[1, 0]), int(val_cm[1, 1])\n",
        "\n",
        "    P, N = tp + fn, tn + fp\n",
        "    den = POS_W * P + NEG_W * N if (POS_W * P + NEG_W * N) > 0 else 1.0\n",
        "    val_weighted_acc = (POS_W * tp + NEG_W * tn) / den\n",
        "\n",
        "    tp_w  = TP_W * tp\n",
        "    prec_w = tp_w / (tp_w + fp) if (tp_w + fp) > 0 else 0.0\n",
        "    rec_w  = tp_w / (tp_w + fn) if (tp_w + fn) > 0 else 0.0\n",
        "    tpf1   = (2.0 * prec_w * rec_w / (prec_w + rec_w)) if (prec_w + rec_w) > 0 else 0.0\n",
        "\n",
        "    print(\n",
        "        f\"Epoch {epoch:04d} | thr={THRESH:.4f} | \"\n",
        "        f\"train_hinge={train_hinge:.4f} | train_acc={train_acc:.3f} | \"\n",
        "        f\"val_hinge={val_hinge:.4f} | val_acc={val_acc:.3f} | \"\n",
        "        f\"bal_acc={val_metrics['balanced_acc']:.3f} | \"\n",
        "        f\"P={prec:.3f} R={rec:.3f} | F1={f1:.3f} | \"\n",
        "        f\"TPF1={tpf1:.3f} (TP_W={TP_W}) | \"\n",
        "        f\"ROC-AUC={val_metrics['roc_auc']:.3f} | PR-AUC={val_metrics['pr_auc']:.3f} | \"\n",
        "        f\"WeightedAcc={val_weighted_acc:.3f} (TP={tp}, TN={tn}, FP={fp}, FN={fn})\"\n",
        "    )\n",
        "\n",
        "    hist[\"epoch\"].append(epoch)\n",
        "    hist[\"train_threshold\"].append(float(THRESH))\n",
        "    hist[\"train_hinge\"].append(float(train_hinge))\n",
        "    hist[\"train_acc\"].append(float(train_acc))\n",
        "    hist[\"val_hinge\"].append(float(val_hinge))\n",
        "    hist[\"val_acc\"].append(float(val_acc))\n",
        "    hist[\"val_bal_acc\"].append(float(val_metrics[\"balanced_acc\"]))\n",
        "    hist[\"val_precision\"].append(float(prec))\n",
        "    hist[\"val_recall\"].append(float(rec))\n",
        "    hist[\"val_roc_auc\"].append(float(val_metrics[\"roc_auc\"]))\n",
        "    hist[\"val_pr_auc\"].append(float(val_metrics[\"pr_auc\"]))\n",
        "    hist[\"val_f1\"].append(float(f1))\n",
        "    hist[\"val_weighted_acc\"].append(float(val_weighted_acc))\n",
        "    hist[\"val_tpf1\"].append(float(tpf1))\n",
        "\n",
        "    if val_hinge < best_val_hinge_seen - 1e-9:\n",
        "        best_val_hinge_seen = float(val_hinge)\n",
        "        best_hinge_epoch = epoch\n",
        "\n",
        "        try:\n",
        "            confusionplot.plot_confusion(val_cm, class_names=(\"TD\", \"ASD\"),\n",
        "                                         normalize=False, outpath=best_hinge_cm_png)\n",
        "            confusionplot.plot_confusion(val_cm, class_names=(\"TD\", \"ASD\"),\n",
        "                                         normalize=True,  outpath=best_hinge_cm_norm_png)\n",
        "            print(f\"  → Saved BEST-HINGE confusion to {best_hinge_cm_png} and {best_hinge_cm_norm_png} \"\n",
        "                  f\"(val_hinge={best_val_hinge_seen:.4f})\")\n",
        "        except Exception as e:\n",
        "            print(\"  ! Could not save BEST-HINGE confusion plot:\", e)\n",
        "\n",
        "        best_hinge_state = {\n",
        "            \"mil_head\": mil_head.state_dict(),\n",
        "            \"epoch\": epoch,\n",
        "            \"selection\": \"best_hinge\",\n",
        "            \"threshold\": float(THRESH), \"top_k\": TOP_K,\n",
        "            \"train_hinge\": float(train_hinge),\n",
        "            \"val_hinge\": float(val_hinge),\n",
        "            \"val_acc\": float(val_acc),\n",
        "            \"val_cm\": val_cm,\n",
        "            \"val_metrics\": val_metrics,\n",
        "            \"tp_weighted_f1\": float(tpf1),\n",
        "            \"encoder_frozen\": True,\n",
        "            \"weights\": {\"pos\": POS_W, \"neg\": NEG_W, \"tp_w\": TP_W},\n",
        "            \"margins\": {\"pos\": MARGIN_POS, \"neg\": MARGIN_NEG},\n",
        "        }\n",
        "        torch.save(best_hinge_state, best_hinge_ckpt_path)\n",
        "        print(f\"  → Saved BEST-HINGE checkpoint to {best_hinge_ckpt_path}\")\n",
        "\n",
        "        with open(best_hinge_csv_path, \"w\", newline=\"\") as f:\n",
        "            w = csv.writer(f)\n",
        "            w.writerow([\n",
        "                \"epoch\", \"threshold\", \"val_hinge\", \"val_acc\", \"balanced_acc\",\n",
        "                \"precision\", \"recall\", \"F1\", \"TPF1\", \"ROC_AUC\", \"PR_AUC\",\n",
        "                \"TP\", \"TN\", \"FP\", \"FN\",\n",
        "                \"cm_png\", \"cm_norm_png\", \"ckpt_path\"\n",
        "            ])\n",
        "            w.writerow([\n",
        "                epoch, float(THRESH), val_hinge, val_acc, val_metrics[\"balanced_acc\"],\n",
        "                prec, rec, f1, tpf1, val_metrics[\"roc_auc\"], val_metrics[\"pr_auc\"],\n",
        "                tp, tn, fp, fn,\n",
        "                best_hinge_cm_png, best_hinge_cm_norm_png, best_hinge_ckpt_path\n",
        "            ])\n",
        "        print(f\"  → Wrote best-hinge CSV: {best_hinge_csv_path}\")\n",
        "\n",
        "    if tpf1 > best_tpf1_seen + 1e-9:\n",
        "        best_tpf1_seen = float(tpf1)\n",
        "        best_tpf1_epoch = epoch\n",
        "\n",
        "        try:\n",
        "            confusionplot.plot_confusion(val_cm, class_names=(\"TD\", \"ASD\"),\n",
        "                                         normalize=False, outpath=best_tpf1_cm_png)\n",
        "            confusionplot.plot_confusion(val_cm, class_names=(\"TD\", \"ASD\"),\n",
        "                                         normalize=True,  outpath=best_tpf1_cm_norm_png)\n",
        "            print(f\"  → Saved BEST-TPF1 confusion to {best_tpf1_cm_png} and {best_tpf1_cm_norm_png} \"\n",
        "                  f\"(TPF1={best_tpf1_seen:.4f})\")\n",
        "        except Exception as e:\n",
        "            print(\"  ! Could not save BEST-TPF1 confusion plot:\", e)\n",
        "\n",
        "        best_tpf1_state = {\n",
        "            \"mil_head\": mil_head.state_dict(),\n",
        "            \"epoch\": epoch,\n",
        "            \"selection\": \"best_tpf1\",\n",
        "            \"threshold\": float(THRESH), \"top_k\": TOP_K,\n",
        "            \"train_hinge\": float(train_hinge),\n",
        "            \"val_hinge\": float(val_hinge),\n",
        "            \"val_acc\": float(val_acc),\n",
        "            \"val_cm\": val_cm,\n",
        "            \"val_metrics\": val_metrics,\n",
        "            \"tp_weighted_f1\": float(tpf1),\n",
        "            \"encoder_frozen\": True,\n",
        "            \"weights\": {\"pos\": POS_W, \"neg\": NEG_W, \"tp_w\": TP_W},\n",
        "            \"margins\": {\"pos\": MARGIN_POS, \"neg\": MARGIN_NEG},\n",
        "        }\n",
        "        torch.save(best_tpf1_state, best_tpf1_ckpt_path)\n",
        "        print(f\"  → Saved BEST-TPF1 checkpoint to {best_tpf1_ckpt_path}\")\n",
        "\n",
        "        with open(best_tpf1_csv_path, \"w\", newline=\"\") as f:\n",
        "            w = csv.writer(f)\n",
        "            w.writerow([\n",
        "                \"epoch\", \"threshold\", \"val_hinge\", \"val_acc\", \"balanced_acc\",\n",
        "                \"precision\", \"recall\", \"F1\", \"TPF1\", \"ROC_AUC\", \"PR_AUC\",\n",
        "                \"TP\", \"TN\", \"FP\", \"FN\",\n",
        "                \"cm_png\", \"cm_norm_png\", \"ckpt_path\"\n",
        "            ])\n",
        "            w.writerow([\n",
        "                epoch, float(THRESH), val_hinge, val_acc, val_metrics[\"balanced_acc\"],\n",
        "                prec, rec, f1, tpf1, val_metrics[\"roc_auc\"], val_metrics[\"pr_auc\"],\n",
        "                tp, tn, fp, fn,\n",
        "                best_tpf1_cm_png, best_tpf1_cm_norm_png, best_tpf1_ckpt_path\n",
        "            ])\n",
        "        print(f\"  → Wrote best-TPF1 CSV: {best_tpf1_csv_path}\")\n",
        "\n",
        "\n",
        "\n",
        "if best_hinge_state is not None:\n",
        "    m = best_hinge_state.get(\"val_metrics\", {})\n",
        "    print(f\"\\nBest-by-HINGE @ epoch={best_hinge_epoch} | \"\n",
        "          f\"val_hinge={best_hinge_state['val_hinge']:.4f} | \"\n",
        "          f\"val_acc={best_hinge_state['val_acc']:.3f} | \"\n",
        "          f\"balanced_acc={m.get('balanced_acc', float('nan')):.3f} | \"\n",
        "          f\"P={m.get('precision', float('nan')):.3f} R={m.get('recall', float('nan')):.3f} | \"\n",
        "          f\"TPF1={best_hinge_state.get('tp_weighted_f1', float('nan')):.3f}\")\n",
        "else:\n",
        "    print(\"\\nNo best-hinge state captured.\")\n",
        "\n",
        "if best_tpf1_state is not None:\n",
        "    m = best_tpf1_state.get(\"val_metrics\", {})\n",
        "    print(f\"\\nBest-by-TPF1 @ epoch={best_tpf1_epoch} | \"\n",
        "          f\"val_hinge={best_tpf1_state['val_hinge']:.4f} | \"\n",
        "          f\"val_acc={best_tpf1_state['val_acc']:.3f} | \"\n",
        "          f\"balanced_acc={m.get('balanced_acc', float('nan')):.3f} | \"\n",
        "          f\"P={m.get('precision', float('nan')):.3f} R={m.get('recall', float('nan')):.3f} | \"\n",
        "          f\"TPF1={best_tpf1_state.get('tp_weighted_f1', float('nan')):.3f}\")\n",
        "else:\n",
        "    print(\"\\nNo best-TPF1 state captured.\")\n",
        "\n",
        "with open(csv_path, \"w\", newline=\"\") as f:\n",
        "    w = csv.writer(f)\n",
        "    w.writerow([\n",
        "        \"epoch\", \"train_hinge\", \"train_acc\",\n",
        "        \"val_hinge\", \"val_acc\", \"val_bal_acc\",\n",
        "        \"val_precision\", \"val_recall\", \"val_f1\",\n",
        "        \"val_roc_auc\", \"val_pr_auc\", \"val_weighted_acc\", \"val_tpf1\"\n",
        "    ])\n",
        "    for i in range(len(hist[\"epoch\"])):\n",
        "        w.writerow([\n",
        "            hist[\"epoch\"][i], hist[\"train_hinge\"][i], hist[\"train_acc\"][i],\n",
        "            hist[\"val_hinge\"][i], hist[\"val_acc\"][i], hist[\"val_bal_acc\"][i],\n",
        "            hist[\"val_precision\"][i], hist[\"val_recall\"][i], hist[\"val_f1\"][i],\n",
        "            hist[\"val_roc_auc\"][i], hist[\"val_pr_auc\"][i], hist[\"val_weighted_acc\"][i], hist[\"val_tpf1\"][i],\n",
        "        ])\n",
        "print(f\"[CSV saved] {csv_path}\")\n",
        "\n",
        "try:\n",
        "    from IPython.display import FileLink, display\n",
        "    display(FileLink(csv_path))\n",
        "    display(FileLink(best_hinge_csv_path))\n",
        "    display(FileLink(best_tpf1_csv_path))\n",
        "except Exception:\n",
        "    pass\n",
        "\n",
        "plt.figure()\n",
        "plt.plot(hist[\"epoch\"], hist[\"train_hinge\"], label=\"train_hinge\")\n",
        "plt.plot(hist[\"epoch\"], hist[\"val_hinge\"], label=\"val_hinge\")\n",
        "plt.xlabel(\"Epoch\"); plt.ylabel(\"Hinge loss\")\n",
        "plt.title(\"MIL training and validation hinge\")\n",
        "plt.legend(); plt.tight_layout()\n",
        "plt.savefig(curves_png_loss, dpi=160); plt.close()\n",
        "print(f\"Saved loss curve to {curves_png_loss}\")\n",
        "\n",
        "plt.figure()\n",
        "plt.plot(hist[\"epoch\"], hist[\"train_acc\"], label=\"train_acc\")\n",
        "plt.plot(hist[\"epoch\"], hist[\"val_acc\"], label=\"val_acc\")\n",
        "plt.plot(hist[\"epoch\"], hist[\"val_bal_acc\"], label=\"val_bal_acc\")\n",
        "plt.xlabel(\"Epoch\"); plt.ylabel(\"Accuracy\")\n",
        "plt.title(\"MIL train/validation accuracy (incl. balanced)\")\n",
        "plt.legend(); plt.tight_layout()\n",
        "plt.savefig(curves_png_acc, dpi=160); plt.close()\n",
        "print(f\"Saved accuracy curve to {curves_png_acc}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LFgVWfbJxVgr"
      },
      "outputs": [],
      "source": [
        "importlib.reload(confusionplot)\n",
        "\n",
        "ckpt, shown_pngs, tag = confusionplot.load_confusion_from_csv(\n",
        "    \"mil_runs/bag_manual_20250908-233147.csv\",\n",
        "    mil_head=mil_head,\n",
        "    device=device,\n",
        "    kind=\"bestTPF1\",   # or \"best\" / \"hinge\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5RMW33sJxVgr"
      },
      "outputs": [],
      "source": [
        "from IPython.display import Image, display\n",
        "display(Image(filename=\"mil_runs/bag_manual_20250908-185447_loss.png\"))\n",
        "display(Image(filename=\"mil_runs/bag_manual_20250908-185447_acc.png\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z0SVzD2KxVgr"
      },
      "outputs": [],
      "source": [
        "import evaluater\n",
        "importlib.reload(evaluater)\n",
        "import json\n",
        "qual = evaluater.extract_correct_asd_example_and_instance(\n",
        "    sequences=sequences,\n",
        "    labels_tensor=labels_tensor,\n",
        "    val_ids=val_ids,\n",
        "    encoder=encoder,\n",
        "    mil_head=mil_head,\n",
        "    context_length=context_length,\n",
        "    stride=slide_stride,\n",
        "    device=device,\n",
        "    pad_short=True,\n",
        "    k=TOP_K,\n",
        "    threshold=THRESH,\n",
        "    run_dir=run_dir,\n",
        "    tag=tag,\n",
        "    save_prefix=\"qual_ASD\"\n",
        ")\n",
        "\n",
        "print(\"Qualitative example:\", json.dumps(qual, indent=2) if qual else \"None\")\n",
        "if tp > 0:\n",
        "    try:\n",
        "        qual = evaluater.extract_correct_asd_example_and_instance(\n",
        "            sequences=sequences,\n",
        "            labels_tensor=labels_tensor,\n",
        "            val_ids=val_ids,\n",
        "            encoder=encoder,\n",
        "            mil_head=mil_head,\n",
        "            context_length=context_length,\n",
        "            stride=slide_stride,\n",
        "            device=device,\n",
        "            pad_short=True,\n",
        "            k=TOP_K,\n",
        "            threshold=THRESH,\n",
        "            run_dir=run_dir,\n",
        "            tag=tag,\n",
        "            save_prefix=f\"qual_ASD_epoch{epoch}\"\n",
        "        )\n",
        "        if qual:\n",
        "            print(\"  → Qual saved:\",\n",
        "                  qual[\"paths\"][\"plot_png\"] if \"paths\" in qual and qual[\"paths\"][\"plot_png\"] else \"(no plot)\")\n",
        "    except Exception as e:\n",
        "        print(\"  ! Qual extraction failed:\", e)\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.21"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}